{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QenSFAOCYpXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e942b937-5b98-4b7c-ee08-c8f9cbb387fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7 keras gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz"
      ],
      "metadata": {
        "id": "tp0p6KtbYp2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db9faf0-3b83-419f-da63-d4d8fcc131c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz\n",
            "To: /content/small_data_set.zip\n",
            "100% 2.07G/2.07G [00:30<00:00, 67.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, zip_file_path, dataset_folder=\"dataset\", image_size=(150, 150), batch_size=32):\n",
        "        self.zip_file_path = zip_file_path\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def extract_zip(self):\n",
        "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_folder)\n",
        "        print(\"Dataset extracted successfully.\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "        self.train_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "        self.validation_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"validation\"\n",
        "        )\n",
        "        self.num_classes = len(self.train_data.class_indices)\n",
        "        print(f\"Data prepared for training and validation. Number of classes: {self.num_classes}\")\n",
        "\n",
        "    def create_model(self):\n",
        "        base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(*self.image_size, 3))\n",
        "        base_model.trainable = False\n",
        "        \n",
        "        self.model = models.Sequential([\n",
        "            base_model,\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        print(\"Deep neural network model created and compiled.\")\n",
        "\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.validation_data\n",
        "        )\n",
        "        print(\"Model trained successfully.\")\n",
        "\n",
        "\n",
        "zip_file_path = \"/content/small_data_set.zip\"\n",
        "\n",
        "classifier = ImageClassifier(zip_file_path)\n",
        "classifier.extract_zip()\n",
        "classifier.prepare_data()\n",
        "classifier.create_model()\n",
        "classifier.train()"
      ],
      "metadata": {
        "id": "6ppqEGzgYp8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c5dcae-b59c-4d85-eba7-58c70a1fce67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Data prepared for training and validation. Number of classes: 5\n",
            "Deep neural network model created and compiled.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 200s 28s/step - loss: 4.0039 - accuracy: 0.2350 - val_loss: 1.7160 - val_accuracy: 0.2800\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 180s 25s/step - loss: 1.1587 - accuracy: 0.4900 - val_loss: 1.1322 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 179s 29s/step - loss: 0.6153 - accuracy: 0.8000 - val_loss: 1.0952 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 185s 29s/step - loss: 0.3520 - accuracy: 0.9300 - val_loss: 0.9790 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 180s 25s/step - loss: 0.2713 - accuracy: 0.9350 - val_loss: 0.9915 - val_accuracy: 0.6400\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 182s 26s/step - loss: 0.1877 - accuracy: 0.9550 - val_loss: 0.8982 - val_accuracy: 0.6800\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 196s 28s/step - loss: 0.1217 - accuracy: 0.9700 - val_loss: 0.9610 - val_accuracy: 0.6600\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 182s 29s/step - loss: 0.0943 - accuracy: 0.9950 - val_loss: 0.8983 - val_accuracy: 0.6600\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 177s 25s/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.8789 - val_accuracy: 0.6800\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 184s 26s/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.6600\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}