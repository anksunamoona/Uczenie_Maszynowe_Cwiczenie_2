{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSH2hdXd-Qc",
        "outputId": "6f7a8119-0423-4772-d63c-b9a8fb9f5ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7 keras gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DhE9aPSeJ5-",
        "outputId": "bb93a32f-818a-4dd9-c050-31f498058f1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz\n",
            "To: /content/small_data_set.zip\n",
            "100% 2.07G/2.07G [00:12<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, zip_file_path, dataset_folder=\"dataset\", image_size=(150, 150), batch_size=32):\n",
        "        self.zip_file_path = zip_file_path\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def extract_zip(self):\n",
        "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_folder)\n",
        "        print(\"Dataset extracted successfully.\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "        self.train_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "        self.validation_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"validation\"\n",
        "        )\n",
        "        self.num_classes = len(self.train_data.class_indices)\n",
        "        print(f\"Data prepared for training and validation. Number of classes: {self.num_classes}\")\n",
        "\n",
        "    def create_model(self):\n",
        "        self.model = models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(*self.image_size, 3)),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation=\"relu\"), #Dodatkowa warstwa\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"sigmoid\") #Inna funkcja aktywacji\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        print(\"Deep neural network model created and compiled.\")\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.validation_data\n",
        "        )\n",
        "        print(\"Model trained successfully.\")\n",
        "\n",
        "zip_file_path = \"/content/small_data_set.zip\"\n",
        "\n",
        "classifier = ImageClassifier(zip_file_path)\n",
        "classifier.extract_zip()\n",
        "classifier.prepare_data()\n",
        "classifier.create_model()\n",
        "classifier.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yHXPXcBeN3D",
        "outputId": "253b21b8-9cfe-4c44-c73c-dd8bd638c2ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Data prepared for training and validation. Number of classes: 5\n",
            "Deep neural network model created and compiled.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 168s 25s/step - loss: 1.6387 - accuracy: 0.1700 - val_loss: 1.6054 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 152s 24s/step - loss: 1.6049 - accuracy: 0.2350 - val_loss: 1.5983 - val_accuracy: 0.2400\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 154s 22s/step - loss: 1.5435 - accuracy: 0.2950 - val_loss: 1.5308 - val_accuracy: 0.2200\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 149s 22s/step - loss: 1.5168 - accuracy: 0.3250 - val_loss: 1.4603 - val_accuracy: 0.3400\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 148s 21s/step - loss: 1.4452 - accuracy: 0.4000 - val_loss: 1.5751 - val_accuracy: 0.3000\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 146s 24s/step - loss: 1.4459 - accuracy: 0.4300 - val_loss: 1.4014 - val_accuracy: 0.3800\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 153s 22s/step - loss: 1.3355 - accuracy: 0.4650 - val_loss: 1.4285 - val_accuracy: 0.3800\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 149s 22s/step - loss: 1.2321 - accuracy: 0.5050 - val_loss: 1.6642 - val_accuracy: 0.2800\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 153s 22s/step - loss: 1.2044 - accuracy: 0.5350 - val_loss: 1.4777 - val_accuracy: 0.4200\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 157s 23s/step - loss: 1.1730 - accuracy: 0.5400 - val_loss: 1.4729 - val_accuracy: 0.4400\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}