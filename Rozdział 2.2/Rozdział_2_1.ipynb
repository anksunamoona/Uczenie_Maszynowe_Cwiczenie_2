{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSH2hdXd-Qc",
        "outputId": "6f7a8119-0423-4772-d63c-b9a8fb9f5ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7 keras gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DhE9aPSeJ5-",
        "outputId": "bb93a32f-818a-4dd9-c050-31f498058f1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz\n",
            "To: /content/small_data_set.zip\n",
            "100% 2.07G/2.07G [00:12<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, zip_file_path, dataset_folder=\"dataset\", image_size=(150, 150), batch_size=32):\n",
        "        self.zip_file_path = zip_file_path\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def extract_zip(self):\n",
        "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_folder)\n",
        "        print(\"Dataset extracted successfully.\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "        self.train_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "        self.validation_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"validation\"\n",
        "        )\n",
        "        self.num_classes = len(self.train_data.class_indices)\n",
        "        print(f\"Data prepared for training and validation. Number of classes: {self.num_classes}\")\n",
        "\n",
        "    def create_model(self):\n",
        "        self.model = models.Sequential([\n",
        "            layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(*self.image_size, 3)),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        print(\"Deep neural network model created and compiled.\")\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.validation_data\n",
        "        )\n",
        "        print(\"Model trained successfully.\")"
      ],
      "metadata": {
        "id": "5yHXPXcBeN3D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = \"/content/small_data_set.zip\"\n",
        "\n",
        "classifier = ImageClassifier(zip_file_path)\n",
        "classifier.extract_zip()\n",
        "classifier.prepare_data()\n",
        "classifier.create_model()\n",
        "classifier.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CNwUp3yeSK8",
        "outputId": "d726f40b-b245-40b9-8949-0e2460e50dd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Data prepared for training and validation. Number of classes: 5\n",
            "Deep neural network model created and compiled.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 173s 25s/step - loss: 2.7442 - accuracy: 0.1250 - val_loss: 1.6016 - val_accuracy: 0.2400\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 150s 22s/step - loss: 1.5789 - accuracy: 0.2400 - val_loss: 1.5523 - val_accuracy: 0.2600\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 155s 23s/step - loss: 1.5127 - accuracy: 0.3050 - val_loss: 1.4862 - val_accuracy: 0.3200\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 141s 20s/step - loss: 1.4447 - accuracy: 0.4150 - val_loss: 1.4251 - val_accuracy: 0.3600\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 150s 24s/step - loss: 1.2590 - accuracy: 0.4350 - val_loss: 1.5080 - val_accuracy: 0.3200\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 150s 22s/step - loss: 1.0993 - accuracy: 0.6050 - val_loss: 1.4668 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 153s 25s/step - loss: 0.8510 - accuracy: 0.6750 - val_loss: 1.5644 - val_accuracy: 0.4400\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 154s 22s/step - loss: 0.6439 - accuracy: 0.7800 - val_loss: 1.7367 - val_accuracy: 0.4200\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 151s 22s/step - loss: 0.4843 - accuracy: 0.8400 - val_loss: 2.1384 - val_accuracy: 0.3200\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 154s 23s/step - loss: 0.3593 - accuracy: 0.9150 - val_loss: 2.1465 - val_accuracy: 0.3600\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}