{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSH2hdXd-Qc",
        "outputId": "6a0164fe-418d-49ee-8e47-00258d735dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7 keras gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DhE9aPSeJ5-",
        "outputId": "fae666a1-584c-4f92-d971-a16e0ecc4816"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz\n",
            "To: /content/small_data_set.zip\n",
            "100% 2.07G/2.07G [00:18<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, zip_file_path, dataset_folder=\"dataset\", image_size=(150, 150), batch_size=32):\n",
        "        self.zip_file_path = zip_file_path\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def extract_zip(self):\n",
        "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_folder)\n",
        "        print(\"Dataset extracted successfully.\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "        self.train_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "        self.validation_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"validation\"\n",
        "        )\n",
        "        self.num_classes = len(self.train_data.class_indices)\n",
        "        print(f\"Data prepared for training and validation. Number of classes: {self.num_classes}\")\n",
        "\n",
        "    def create_model(self):\n",
        "        self.model = models.Sequential([\n",
        "            layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(*self.image_size, 3)),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(128, (3, 3), activation=\"relu\"), #Dodatkowa warstwa\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(256, (3, 3), activation=\"relu\"), #Dodatkowa warstwa\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\") \n",
        "        ])\n",
        "        self.model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        print(\"Deep neural network model created and compiled.\")\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.validation_data\n",
        "        )\n",
        "        print(\"Model trained successfully.\")\n",
        "\n",
        "zip_file_path = \"/content/small_data_set.zip\"\n",
        "\n",
        "classifier = ImageClassifier(zip_file_path)\n",
        "classifier.extract_zip()\n",
        "classifier.prepare_data()\n",
        "classifier.create_model()\n",
        "classifier.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yHXPXcBeN3D",
        "outputId": "57bf6491-220e-4f17-ffb7-e56302cbdc5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Data prepared for training and validation. Number of classes: 5\n",
            "Deep neural network model created and compiled.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 163s 24s/step - loss: 1.6218 - accuracy: 0.1950 - val_loss: 1.6091 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 144s 21s/step - loss: 1.6092 - accuracy: 0.2000 - val_loss: 1.6061 - val_accuracy: 0.2200\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 149s 22s/step - loss: 1.6029 - accuracy: 0.2050 - val_loss: 1.5889 - val_accuracy: 0.2200\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 128s 19s/step - loss: 1.5878 - accuracy: 0.2450 - val_loss: 1.6052 - val_accuracy: 0.1800\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 128s 18s/step - loss: 1.5699 - accuracy: 0.2900 - val_loss: 1.6256 - val_accuracy: 0.2200\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 145s 21s/step - loss: 1.5596 - accuracy: 0.2400 - val_loss: 1.5714 - val_accuracy: 0.2600\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 150s 24s/step - loss: 1.4973 - accuracy: 0.3150 - val_loss: 1.5992 - val_accuracy: 0.3000\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 143s 21s/step - loss: 1.5109 - accuracy: 0.3200 - val_loss: 1.5751 - val_accuracy: 0.3000\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 129s 19s/step - loss: 1.4532 - accuracy: 0.3700 - val_loss: 1.4861 - val_accuracy: 0.2800\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 144s 21s/step - loss: 1.4508 - accuracy: 0.3350 - val_loss: 1.5266 - val_accuracy: 0.2600\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}