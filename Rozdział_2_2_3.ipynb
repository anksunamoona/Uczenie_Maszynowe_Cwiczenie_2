{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSH2hdXd-Qc",
        "outputId": "8b1c0b17-f91f-43ef-d9e5-1802199fd873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7 keras gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DhE9aPSeJ5-",
        "outputId": "e7f7dee0-0b73-4be8-b20f-6da04d8b2277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1T5Cm4Tt1sO21ARz6BvStSW4yks118rRz \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "class ImageClassifier:\n",
        "    def __init__(self, zip_file_path, dataset_folder=\"dataset\", image_size=(150, 150), batch_size=32):\n",
        "        self.zip_file_path = zip_file_path\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def extract_zip(self):\n",
        "        with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_folder)\n",
        "        print(\"Dataset extracted successfully.\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "        self.train_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"training\"\n",
        "        )\n",
        "\n",
        "        self.validation_data = data_gen.flow_from_directory(\n",
        "            self.dataset_folder,\n",
        "            target_size=self.image_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\",\n",
        "            subset=\"validation\"\n",
        "        )\n",
        "        self.num_classes = len(self.train_data.class_indices)\n",
        "        print(f\"Data prepared for training and validation. Number of classes: {self.num_classes}\")\n",
        "\n",
        "    def create_model(self):\n",
        "        self.model = models.Sequential([\n",
        "            layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=(*self.image_size, 3)),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(128, (3, 3), activation=\"relu\"), #Dodatkowa warstwa\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(256, (3, 3), activation=\"relu\"), #Dodatkowa warstwa\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\") \n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer=\"adagrad\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) #Inny optimazer, zmieniono adam na sgd\n",
        "        print(\"Deep neural network model created and compiled.\")\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            epochs=epochs,\n",
        "            validation_data=self.validation_data\n",
        "        )\n",
        "        print(\"Model trained successfully.\")\n",
        "\n",
        "zip_file_path = \"/content/small_data_set.zip\"\n",
        "\n",
        "classifier = ImageClassifier(zip_file_path)\n",
        "classifier.extract_zip()\n",
        "classifier.prepare_data()\n",
        "classifier.create_model()\n",
        "classifier.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yHXPXcBeN3D",
        "outputId": "e9858a28-a9a0-4b72-ed2a-eb6d3fcd7ec5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully.\n",
            "Found 200 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n",
            "Data prepared for training and validation. Number of classes: 5\n",
            "Deep neural network model created and compiled.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 168s 25s/step - loss: 1.6105 - accuracy: 0.2050 - val_loss: 1.6097 - val_accuracy: 0.2000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 148s 22s/step - loss: 1.6100 - accuracy: 0.2200 - val_loss: 1.6095 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 145s 23s/step - loss: 1.6097 - accuracy: 0.2000 - val_loss: 1.6093 - val_accuracy: 0.1800\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 144s 21s/step - loss: 1.6097 - accuracy: 0.2200 - val_loss: 1.6091 - val_accuracy: 0.1800\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 151s 22s/step - loss: 1.6092 - accuracy: 0.2400 - val_loss: 1.6089 - val_accuracy: 0.1800\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 147s 21s/step - loss: 1.6088 - accuracy: 0.2450 - val_loss: 1.6087 - val_accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 144s 23s/step - loss: 1.6086 - accuracy: 0.2700 - val_loss: 1.6086 - val_accuracy: 0.1800\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 144s 21s/step - loss: 1.6083 - accuracy: 0.2350 - val_loss: 1.6084 - val_accuracy: 0.1800\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 147s 22s/step - loss: 1.6078 - accuracy: 0.2200 - val_loss: 1.6082 - val_accuracy: 0.1800\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 144s 21s/step - loss: 1.6074 - accuracy: 0.2300 - val_loss: 1.6081 - val_accuracy: 0.2200\n",
            "Model trained successfully.\n"
          ]
        }
      ]
    }
  ]
}